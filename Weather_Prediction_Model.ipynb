{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading dataset\n",
    "df_WT_Phoenix_2013=pd.read_excel(open('Phoenix climate date_2013_ 2015.xlsx', 'rb'),sheet_name='Phoenix 2013') \n",
    "df_WT_Phoenix_2013=df_WT_Phoenix_2013.rename(columns={\"Unnamed: 0\": \"Hour\"})\n",
    "df_WT_Phoenix_2013=df_WT_Phoenix_2013.iloc[:,:16]\n",
    "\n",
    "#Cleaning dataset\n",
    "df_WT_Phoenix_2013=df_WT_Phoenix_2013.dropna(axis=1, thresh=len(df_WT_Phoenix_2013['Hour'].values)*0.80);\n",
    "df_WT_Phoenix_2013=df_WT_Phoenix_2013.drop(columns=['Hour','Temp (C )','sind_spd (m/s)','date'])\n",
    "\n",
    "#3 days dataset ready\n",
    "X=df_WT_Phoenix_2013.iloc[:,:-1]\n",
    "Y=df_WT_Phoenix_2013.iloc[2:,-1]\n",
    "le = preprocessing.LabelEncoder()\n",
    "D2=X.iloc[:-2,:];\n",
    "D1=X.iloc[1:-1,:];\n",
    "D0=X.iloc[2:,:];\n",
    "\n",
    "#Columns create\n",
    "Column_DBY=[];\n",
    "Column_Y=[];\n",
    "Column_T=[];\n",
    "Col=D2.columns;\n",
    "for col in Col:\n",
    "    Column_DBY.append('DBY_'+str(col))\n",
    "    Column_Y.append('Y_'+str(col))\n",
    "    Column_T.append('T_'+str(col))\n",
    "dictionary_DBY = dict(zip(D2.columns, Column_DBY))   \n",
    "dictionary_Y = dict(zip(D1.columns, Column_Y)) \n",
    "dictionary_T = dict(zip(D0.columns, Column_T)) \n",
    "\n",
    "#New DataFrame Ready\n",
    "DF=pd.concat([D2.rename(columns=dictionary_DBY).reset_index(),D1.rename(columns=dictionary_Y).reset_index(),D0.rename(columns=dictionary_T).reset_index()],axis=1)\n",
    "DF=DF.drop(columns=['index']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D2=X.iloc[:-2,:];\n",
    "D1=X.iloc[1:-1,:];\n",
    "D0=X.iloc[2:,:];\n",
    "\n",
    "#Columns create\n",
    "Column_DBY=[];\n",
    "Column_Y=[];\n",
    "Column_T=[];\n",
    "Col=D2.columns;\n",
    "for col in Col:\n",
    "    Column_DBY.append('DBY_'+str(col))\n",
    "    Column_Y.append('Y_'+str(col))\n",
    "    Column_T.append('T_'+str(col))\n",
    "dictionary_DBY = dict(zip(D2.columns, Column_DBY))   \n",
    "dictionary_Y = dict(zip(D1.columns, Column_Y)) \n",
    "dictionary_T = dict(zip(D0.columns, Column_T)) \n",
    "\n",
    "#New DataFrame Ready\n",
    "DF=pd.concat([D2.rename(columns=dictionary_DBY).reset_index(),D1.rename(columns=dictionary_Y).reset_index(),D0.rename(columns=dictionary_T).reset_index()],axis=1)\n",
    "DF=DF.drop(columns=['index']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1=['Partly Cloudy', 'Scattered Clouds', 'Mostly Cloudy', 'Overcast'] #Cloudy\n",
    "R2=['Haze', 'Widespread Dust', 'Unknown'] #Other\n",
    "R3=['Rain', 'Thunderstorm', 'Thunderstorms and Rain', 'Thunderstorms with Hail','Heavy Rain','Heavy Thunderstorms and Rain','Light Rain','Light Thunderstorms and Rain'];\n",
    "R=[R1,R2,R3]\n",
    "Out=['Cloudy','Other','Rainy']\n",
    "for i in range(len(R)):\n",
    "    for j in range(len(R[i])):\n",
    "        Y=Y.replace(R[i][j],Out[i]);    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=le.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot encoding\n",
    "DF=DF.replace(0,np.nan);\n",
    "DF_cat=pd.get_dummies(DF,columns=['DBY_dir','Y_dir','T_dir']);\n",
    "#Imputing\n",
    "fill_NaN = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputed_DF = pd.DataFrame(fill_NaN.fit_transform(DF_cat))\n",
    "imputed_DF.columns = DF_cat.columns\n",
    "imputed_DF.index = DF_cat.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std=StandardScaler()\n",
    "imputed_std=std.fit_transform(imputed_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2290423415743109"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Splitting and model fitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(imputed_std, y, test_size=0.21, random_state=1)\n",
    "\n",
    "gnb=GaussianNB();\n",
    "\n",
    "gnb=gnb.fit(X_train,y_train)\n",
    "\n",
    "y_pred = gnb.predict(X_train)\n",
    "\n",
    "#Accuracy\n",
    "accuracy_score(y_pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rezwa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\rezwa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7158283603296391"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=lr.fit(X_train,y_train)\n",
    "\n",
    "y_pred = lr.predict(X_train)\n",
    "\n",
    "#Accuracy\n",
    "accuracy_score(y_pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
